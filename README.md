# CrawlForge

**CrawlForge** est un framework de scraping web modulaire, flexible et extensible, conÃ§u pour respecter les principes **SOLID**, les **design patterns** et une **architecture logicielle propre**.

## ğŸš€ FonctionnalitÃ©s
- **Architecture modulaire** : facile Ã  Ã©tendre avec de nouvelles stratÃ©gies (BS4, Selenium, APIâ€¦)
- **Respect de SOLID** : code maintenable et Ã©volutif
- **Multiples sorties** : export vers CSV, JSON, bases de donnÃ©es, etc.
- **Parsers interchangeables** : HTML, JSON, XMLâ€¦
- **Tests unitaires** intÃ©grÃ©s dÃ¨s le dÃ©part

## ğŸ— Architecture du projet
CrawlForge/
â”‚
â”œâ”€â”€ core/ # CÅ“ur mÃ©tier
â”‚ â”œâ”€â”€ interfaces/ # Interfaces (Strategy, Parser, Exporter)
â”‚ â”œâ”€â”€ services/ # Services principaux
â”‚ â”œâ”€â”€ models/ # ModÃ¨les de donnÃ©es
â”‚ â””â”€â”€ exceptions.py # Exceptions custom
â”‚
â”œâ”€â”€ strategies/ # MÃ©thodes de scraping (BS4, Seleniumâ€¦)
â”œâ”€â”€ parsers/ # DiffÃ©rents parseurs
â”œâ”€â”€ exporters/ # Exporteurs (CSV, JSON, DBâ€¦)
â”œâ”€â”€ config/ # Configurations
â”œâ”€â”€ tests/ # Tests unitaires et d'intÃ©gration
â””â”€â”€ main.py # Point dâ€™entrÃ©e

bash
Copy code

## ğŸ“¦ Installation
```bash
git clone https://github.com/<ton_user>/CrawlForge.git
cd CrawlForge
pip install -r requirements.txt
ğŸ”§ Utilisation simple
python
Copy code
from strategies.bs4_scraper import BeautifulSoupScraper
from parsers.html_parser import HTMLParser
from exporters.csv_exporter import CSVExporter
from core.services.scraper_service import ScraperService

scraper = ScraperService(
    scraper_strategy=BeautifulSoupScraper(),
    parser=HTMLParser(),
    exporter=CSVExporter("output.csv")
)

scraper.run("https://example.com")
ğŸ§ª Tests
bash
Copy code
pytest
ğŸ¤ Contribution
Les contributions sont les bienvenues !

Forkez le projet

CrÃ©ez votre branche (git checkout -b feature/ma-feature)

Committez (git commit -m 'Ajout de ma feature')

Poussez (git push origin feature/ma-feature)

Ouvrez une Pull Request

ğŸ“œ Licence
MIT License
